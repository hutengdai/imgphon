{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imgphon import helmet \n",
    "from imgphon import imgphon as iph # TODO fix issue with detector and predictor\n",
    "import os, subprocess, glob, re\n",
    "import numpy as np\n",
    "import audiolabel\n",
    "import cv2\n",
    "import dlib\n",
    "from imutils.face_utils import FaceAligner\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tilt normalization on lips directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tSNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "n_tsne_comp = 2\n",
    "X_embedded = TSNE(n_components=n_tsne_comp).fit_transform(analysis)\n",
    "\n",
    "X_df = pd.DataFrame(X_embedded)\n",
    "X_df.columns = [\"D{}\".format(d+1) for d in range(n_tsne_comp)]\n",
    "X_df = X_df.assign(phone=pd.Series(md['uniquePhone']).values)\n",
    "df = df.assign(phase=pd.Series(md['phase']).values)\n",
    "X_df.head(5)\n",
    "sns.lmplot(x=\"D1\", y=\"D2\", data=X_df, \n",
    "             hue=\"phone\", fit_reg=False, size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct manipulations of video files (legacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract and display a single landmark-annotated video frame\n",
    "video = 'SN12_AA032001.MXF'\n",
    "time = '00:00:10.900'\n",
    "\n",
    "frame = get_video_frame(video,time)\n",
    "shape = detect_landmarks(frame)\n",
    "color_corrected = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(draw_landmarks(color_corrected,shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract a frame corresponding to the desired timepoint of an audio file (here, from a TextGrid) \n",
    "# and extracts a polygon of the lip shape\n",
    "babb = 'vowels/P1.MXF'\n",
    "babb_tg = os.path.splitext(babb)[0] + \".TextGrid\"\n",
    "pm = audiolabel.LabelManager(from_file=babb_tg, from_type=\"praat\")\n",
    "v = pm.tier('phone').search(vre)[0] # should only be one match per file; TODO check while running\n",
    "midpoint= v.center\n",
    "ffmpeg_time = str(round(midpoint,3))\n",
    "frame = get_video_frame(babb,ffmpeg_time)\n",
    "shape = detect_landmarks(frame)\n",
    "color_corrected = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(draw_landmarks(color_corrected,shape))\n",
    "\n",
    "image = lip_mask(frame,shape)\n",
    "plt.imshow(crop_center(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clip a short stretch of video from the longer videos typical of ultrasound acquisitions\n",
    "exp_movie = '12-video/SN12_AA032001.MXF'\n",
    "exp_snippet = '12-video/SN12_AA032001_short.MXF'\n",
    "fname = os.path.split(exp_movie)[1]\n",
    "basename = os.path.splitext(fname)[0]\n",
    "\n",
    "# get a snippet of the MXF\n",
    "snippet_args = ['ffmpeg', '-ss', '00:00:30', \n",
    "                '-i', exp_movie, \n",
    "                \"-t\", \"00:00:08\", \n",
    "                \"-vcodec\", \"copy\", \n",
    "                \"-acodec\", \"copy\", \n",
    "                exp_snippet]\n",
    "subprocess.check_call(snippet_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_movie = 'vowels/POO1.MXF'\n",
    "fname = os.path.split(exp_movie)[1]\n",
    "basename = os.path.splitext(fname)[0]\n",
    "\n",
    "subprocess.check_call(['ffmpeg','-loglevel','8','-i',exp_snippet,'-vf','fps=20','img_%05d_f.bmp'])\n",
    "movie = cv2.VideoCapture('img_%05d_f.bmp')\n",
    "\n",
    "frame_num = 1\n",
    "\n",
    "while(movie.isOpened()):\n",
    "    ret, frame = movie.read()\n",
    "    if (ret==False):   # the file is finished\n",
    "        break\n",
    "\n",
    "    # detect face region and draw landmarks on the image.\n",
    "    shape = detect_landmarks(frame)\n",
    "    out_image = draw_landmarks(frame,shape)\n",
    "    \n",
    "    # write the image to a .bmp file, with zero-padding to ensure the frames are input \n",
    "    cv2.imwrite('{0:05d}g.bmp'.format(frame_num), out_image)\n",
    "    frame_num += 1\n",
    "        \n",
    "# cleanup\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# make a gif (a bit slowed down by default) from the output bmps\n",
    "subprocess.check_call(['convert', '*g.bmp', basename+'.gif'])\n",
    "\n",
    "# remove the input bmps\n",
    "for bmp in glob.glob(\"*g.bmp\"):\n",
    "    os.remove(bmp)\n",
    "for bmp in glob.glob(\"*f.bmp\"):\n",
    "    os.remove(bmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
